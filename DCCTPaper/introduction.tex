%! TEX root = main.tex


\section{Introduction}

% I think I need to restructure as the following:
% 1- I will introduce my own consistency level definitions, considering how they
% affect data parts and replias. No need to mention bad sounding EC.
% 2- I will remove bashing on consistency level definitions and everything not
% to the point.
% 3- I will include more language examples, and possible translations, assuming
% that I am storing my data in different databases. 

% Why replicate?
In modern distributed systems, data is often replicated, either partially or totally 
across several nodes. Replication primarily contributes to making distributed 
applications more resilient to failure, and allowing the placement of data closer to clients, 
thus reducing communication delays especially for geo-distributed applications. 
% Problems that need to be solved when replicating
When implemented correctly, replication can greatly improve availability and performance.
However, managing the consistency of replicated data is a well-known, nontrivial
problem. Ideally, all clients must observe the most recent, correct (according to
application specification) data at all times. This ideal consistency model is what
strict serializability transaction isolation level(ref) provides. However, it
is typically costly to maintain this level of consistency. Strict
serializability is commonly implemented using two-phase commit(ref), which does not
tolerate node failure and required a leader, which introduces a single point of
failure. Current advanced approaches, such as Paxos-based commit protocols(refs) or three-phase commit(ref),
require a quorum of replicas to be up, a large number of messages or very
specific domain knowledge. \\  %elaborate later on, good discussion in MDCC paper.

% Do we always need strong consistency?
For many systems, achieving this strong consistency level is unrealistic given
the implied costs. This is why many data management systems do not enable strict
serializability by default (refs). Furthermore, it is possible to enforce many useful, common
application correctness criteria without needing strict serializability. This is
true when it is not needed to observe the latest version of data, such as the
following cases:
% We can use eventual consistency for the following with the following benefits
\begin{enumerate}
% I think talking about all nodes is not correct here, and I did not mention
    % before the relations between number of nodes queried and consistency.
\item Creating twitter-like news feeds. There is no need to query all nodes for
the most recent versions data in order to display a satisfactory news feed.

\item Creating lists of recommended products based on a user's browsing history.
Such lists need not be made immediately available on all nodes, as we can
continue to use slightly out of date lists and view them on rendered pages.

\item Counting views on an article, video, photo...etc. It does not matter if
different clients see different values for such counters, as long as these
views eventually converge to the same value.
\end{enumerate}

We can observe from the previous list, that due to the probabilistic nature and 
inherent non-determinism of many web applications, it is possible to exploit 
eventual consistency, and provide correct (albeit relaxed) application behavior, 
very likely at a cost that is orders of magnitude cheaper than strict serializability 
or other stronger consistency levels. For many commercial distributed storage 
systems, such as Cassandra(ref) or MongoDB(ref), eventual consistency is the default
level, and the default configuration requires contacting only a single node in
order to acknowledge the success of a read or write. \\
%(write also cost in terms of message rounds). 

% However, we cannot enforce all invariants with only eventual consistency
On the other hand, there are use cases where nothing other than strict
serializability (even snapshot isolation will not do) can
satisfy the correctness invariant. Such as:

\begin{enumerate}

\item Assigning non arbitrary, unique identifiers, such as unique user names or
ascending serial numbers.(ref Peter Bailis work)

\item Maintaining consistency of counters supporting arbitrary operations, such
as bank account balance, or stock of an item. 

\item Acquiring a finite resource, such as tickets or airplane seats. 

\item Ensuring that a resource is used only $n$ times, such as resetting a
password with a reset token and using it only once. 
\end{enumerate}

% There are other invariants that require a consistency level in between
 Between these two extremes, there are many other consistency models. For
 instance, the Atomic visibility model(ref) can be used for cases that
 require all parts of a data item to be viewed consistently, but does not require
 the most recent version of a data item. For the following cases, 
 atomic visibility can maintain correctness at a cost lower than strict
 serializability: 
% TODO I think these examples are very abstract. I better replace them with more
% tangible ones. 
\begin{enumerate}
\item Maintaining materialized views.
\item Maintaining foreign key constraints.
\end{enumerate}

%TODO rephrase and throw somewhere else.

In essence, since most data abstractions are not atomic units, in the sense that they
are composed of multiple parts that are replicated, and cannot be updated in the
speed of light, the only way to make data seem consistency all the time is to
delay subsequent interactions with data being manipulated, that is, limit
concurrency with other operations. However, this is not always possible or even
needed. Most data is not related in anyway and can be updated without
coordination, and many readers can tolerate stale data. 

% The problem is that using all these consistency levels in applications 
% is not easy to express or reason about. 
It is not hard to find many distributed applications that include use cases
requiring more than one of the consistency models we described here, such as social media
platforms, e-commerce and online gaming. When these applications must service millions of
clients across the globe correctly, with competitive performance and
availability, selecting the correct consistency policy becomes crucial.
Selecting the strongest policy can have drastically negative effects on availability, while
resorting to eventual consistency can cause violation of correctness invariants.
Support for multiple levels of consistency has always been supported in some
form, ever since relational databases were introduced, in the form of
transaction isolation levels(ref), to current distributed key-value stores.
However, this support, in past and present, has suffered from many problems,
which we go over in the following sections:

%\subsection{Philosophical Divide}
%In recent years, there has been debate on whether to use strong or weak consistency, 
%with researchers and practitioners generally favoring one over the other. This
%divide is clearly reflected in available frameworks. For instance, the first
%releases of Cassandra (since 2008), only supported eventual consistency and not
%concept of transactions, with programmers encouraged to use a relational
%database when needing strong consistency, or a service such as Zookeeper.
%Since 2013, there is very limited support for transactions. On the other hand,
%researchers generally aim to study making strong consistency feasible, with only
%little work on defining eventual consistency semantics (which does not come for
%free) (ref cloud types). Hence, developers requiring multiple
%consistency levels must use multiple tools to achieve this, which is cumbersome,
%and hard to debug and reason about. 
%
%\subsection{Poor Definitions of Consistency}
%The nature of data and operations
%greatly influences the complexity of the consistency policy definition. For
%instance, data can be either one atomic piece, such as data occupying a single
%memory location, in the sense that updating all bits in a memory location seems
%to happen at once, data that is not atomic is harder to reason about. Data can
%also be replicated. Data that is both non-atomic and replicated is even harder
%to reason about. Operations also can be atomic or multi-part (such as
%transactions and multi-statement functions). Yet, many theoretical definitions
%seem to ignore many of these aspects, and many practical definitions define
%either the correctness in terms of replication, or maintaining the coherence of
%multipart data. \\
%
%For instance, linearizability(ref) is concerned with ordering single
%operations over a single data item. While a useful and comprehensible theoretical
%definition, it applies only to a very narrow subset of real-world operation
%abstractions and data representations. It could, for instance be used to model adding
%two numbers that occupy only a single memory location (assuming accesses to
%memory locations are atomic). But it would fail to represent applying the ++
%operator in Java to longs (which occupy two memory locations), not to mention
%modeling transactions touching multiple data items, possibly partitioned over many
%machines and/or replicated. Strict serializability could be thought of as
%linearizability that covers grouped operations (transactions) and groups of
%items. However, it does not cover the semantics of replicated data items.\\
%

\subsection{Data Abstractions}
As important it is to define which data structures represent a logical data
unit, this is not well supported, neither in programming languages, nor in
databases. The fact that certain data items must be updated together can also be
seen by examining operations updating the data, or referring to documentation.
Even the fact that some data is replicated may not be transaparent. A good
example for this is the replication of data across main memory and caches, which
is main source of bugs in concurrent programs. Only a few programming languages,
such as X10, provide programming language constructs for managing replicated and
remote data(ref)

% Maybe later, we do not want too many claims especially that I did not verify
% that no data management thingie does not provide any support for that. 
%\subsection{Poor Support for Multi-level Replication}
%Other than full schema replication



\subsection{No Theory or Good Support for Mixing Consistency Policies}

Because of the separation in the studying and implementing consistency policies.
There has been very little academic work on defining the behavior of a system
that supports multiple consistency policies. Atul Adya(ref) imposes restrictions
on data reads performed by transactions that require strong consistency, if the data was
previously written by transactions with weaker consistency. However, it is not clear
how reads are affected. On the practical side, if programmers are not very
careful, it is hard to achieve desired consistency properties in systems
supporting multiple consistency policies. For instance, in Cassandra, achieving
strong consistency, in the sense that correctly persisted, atomic data is
observed correctly (a row is an atomic unit in Cassandra), requires quorum reads
and quorum writes by different clients, however, even if a single client issues
writes that are acknowledged only by only one node, expected consistency of
other clients cannot be guaranteed. The situation gets even more complicated
when the consistency of multiple operations over non-atomic data is required.

\subsection{What Does Strong and Weak Mean?}
Generally, it is not clear what makes a certain consistency level strong or
weak, and how to define an order of ``strength''.

%How can programmers specify a consistency policy? 
%A consistency policy generally limits possible orderings and concurrency among
%operations executed in parallel over data. 



%For instance, authors of (MDCC) conducted a part of evaluation to their Paxos-based commit
%protocol by comparing the performance of TPC-C transactions when executed under eventual consistency  
%, two-phase commit  and their protocol itself. It is not surprising that in all cases, the eventually
%consistent protocol was by far the most
%performant. However, using only this consistency level cannot guarantee that
%some transactions, such as the product buy request will behave correctly, as
%this would require strong consistency to maintain the invariant that stock must
%remain positive, and one item is not sold to two different people. (assuming
%these are application requirements) \\



%For relational databases,
%transaction isolation levels can be used. In Cassandra, a consistency level can
%be specified for all read-write operations. The problem with such approaches, is
%that correctness invariants are usually described in terms of the state of data
%before and after applying an operation(what refs can I list here?) 
%(e.g a transaction or update function) to
%it. However, it is not always clear what constitutes a data unit, or an
%operation unit. One could argue that a transaction serves as an abstraction of
%an operation unit, but then how can we guarantee that all parts of a data unit
%that need to be updated in order to maintain an invariant are actually updated?
%Even worse, when the data is replicated, it could be that updates to different
%parts of a data unit are propagated out of order, or in different orders to
%different replicas. The consistency of a data unit is also the result of complex
%interactions of reads and writes, and depends on the consistency level of both.
%For instance, for data to be consistent in Cassandra, it is not enough to only
%write to a quorum of nodes for all elements of a data item, but all reads of
%that data item must be from a quorum as well. 

% This is unfortunate given the impact consistency level can have on performance
% and how choosing the wrong level can impact program correctness. I can here
% show evaluation results from MDCC paper.
% (I want to say here that current tools do not provide suitable abstractions to
% represent multi-component, replicated data items, operations units, how to
% enforce consistency requirements on data. I also need to show somewhere that
% consistency is a property of data.)\\

\subsection{Our Proposal}
We have been investigating ways to express consistency properties of
applications, in ways to overcome the above problems. Our proposal builds upon
two important observations that come from the concurrent programming and
database communities. We describe these observations on the following sections.  

\subsubsection{Consistency is a Property of Data}
The consistency level is typically defined on operations, or, in other words, it
is the responsibility of operations to enforce a certain consistency level.
However, we can flip this reasoning if we consider that consistency
invariants are most commonly expressed in terms of transitions from one correct
state of data to the next by applying a sequence of operations (e.g.
transactions), and then examining the validity of the new state
in terms of sequential specifications. It makes sense then , to declare
consistency as a property of data, rather than. Authors of Atomic Jave~\cite{Vaziri:2006:ASC:1111320.1111067} exploit this observation, and
introduce new programming language constructs that allow expressing whether
accesses to annotated data sets should be linearizable. The language compiler
then actually inserts synchronization constructs whenever needed. We have extended
their proposal to support declaring data sets with consistency policies other
than linearizability. We will cover atomic sets in more detail along with our
extensions in Section 2.1. \\

\subsubsection{Consistency Properties are not Temporal}
The second observation is that, correctness invariants over data are not temporal, hence
neither is the consistency level needed to maintain it. This was explained
in~\cite{bailis2014coordination} (the case for
invariant-based...bailis). This means that attaching fixed consistency levels to
data sets does not sacrifice the expressiveness or flexibility of consistnency
policy specifications, and at the same time allows tractable specification and checking of
correctness, compatibility and composability of consistency policies over
several data sets. We will cover the model which describes restrictions on
transactions modifying different data sets at different consistency levels in
section ??? \\

% We propose a solution, based on observing that invariants on data are not
% temporal, as shown by Bailis, also shown before in the work on atomic sets.
In this paper, we present Data Centric Cloud Types, a programming language that
exploits the previous two observations to encode consistency properties as data
types. These types also make replication and logical data groups concrete and
explicit. Our language is built as an extension to Cloud Types (ref), 
a distributed programming language that provides high-level abstractions to replicated
data and operations applied to it, and guarantees eventual consistency. 
The design of our language supports expressing common denormalization(ref) patterns used when designing distributed
data schemas. It also supports specifying consistency requirements for views as
a core issue not an orthogonal one. The runtime of our language makes use of
types encoding 
consistency information to allow more concurrent operations, potentially
improving performance. We will talk more about cloud types in Section 2.2. \\

The rest of this paper is organized as follows: In Section 2 we overview related
work we employed to design and implement the language and its runtime,
Section 3 formally describes our model of data items, operations, consistency
levels and their interactions. Section 4 formally describes our language's syntax and
semantics. In Section 5, we describe how the runtime of the language orders
read/write operations through the commit protocol, exploiting consistency types. 
Section 6 describes the current implementation of the language and shows preliminary evaluation
results. Finally, Section 7 outlines future work and concludes. 

% The idea is to attach consistency policies to data. In the work of atomic
% sets, it is not clear how transactions working on different sets interact and
% how they should be ordered. We contribute by showing how to order them in a
% way that preseves correctness, depending on work by Adya.

% We outline the language specification that contains sets with policies, which
% is built on top of Cloud types language.

% We show examples of common use cases, consistency policies attached and so on.

% Then we go further and show the commit protocol, which orders transactions and
% specifies the number of replicas to be contacted, what is really useful here
% is that the cost model becomes clearer (really?) 

% Finally we discuss future extensions and possible integration with current
% storage systems or languages. 
% Replication requires every write issued by system clients to be
% propagated across all replicas. Furthermore, concurrent, or out-of-order writes
% must be ordered in a way that does not violate application correctness criteria.  


