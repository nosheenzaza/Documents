%! TEX root = main.tex


\section{Introduction}

% Why replicate?
In modern distributed systems, data is often replicated, either partially or totally 
across several nodes. Replication primarily contributes to making distributed 
applications more resilient to failure, and allowing the placement of data closer to clients, 
thus reducing communication delays especially for geo-distributed applications. 
% Problems that need to be solved when replicating
When implemented correctly, replication can greatly improve availability and performance.
However, managing the consistency of replicated data is a well-known, nontrivial
problem. Ideally, all clients must observe the most recent, correct (according to
application specification) data at all times. This ideal consistency model is what
strict serializability transaction isolation level (ref) provides. However, it
is typically costly to provide this level of consistency.  Strict
serializability is commonly implemented using two-phase commit(ref), which does not
tolerate node failure and required a leader, which introduces a single point of
failure. Current advanced
approaches, such as paxos-based commit protocols(refs) or three-phase commit(ref),
require a quorum of replicas to be up, a large number of messages or very
specific domain knowledge. \\  %elaborate later on, good discussion in MDCC paper.

% Do we always need strong consistency?
For many systems, achieving this strong consistency level is unrealistic given
the implied costs. Furthermore, it is possible to enforce many useful and common
application correctness criteria without needing strict serializability. 
% We can use eventual consistency for the following with the following benefits
For instance, we can rely solely on eventual consistency, while still providing
reasonable application behavior for many use-cases, such as:

\begin{enumerate}
\item Creating twitter-like news feeds. There is no need to query all nodes for
the most recent versions data in order to display a satisfactory news feed.

\item Creating lists of recommended products based on a user's browse history.
Such lists need not be made immediately available on all nodes, as we can
continue to use slightly out of data lists and view them on rendered pages.

\item Counting views on an article, video, photo...etc: It does not matter if
different clients see different values for such counters, as long as these
views eventually converge to the same value.
\end{enumerate}

We can observe from the previous list, that due to the probabilistic nature and 
inherent non-determinism of many Internet applications, it is possible to exploit 
eventual consistency, and provide correct (albeit relaxed) application behavior, 
very likely at a cost that is orders of magnitude cheaper than strict serializability 
or other stronger consistency levels. 

% How common is eventual consistency? What is the possible cost?
For many commercial distributed storage
systems, such as Cassandra(ref) or MongoDB (ref), eventual consistency is the default
level, and the default configuration requires contacting only a single node in
order to acknowledge the success of a read or write. (write also cost in terms
of message rounds).

% However, we cannot enforce all invariants with only eventual consistency
Of course, there are use cases where nothing other than strong consistency can
satisfy the correctness invariant. Such as:

\begin{enumerate}

\item Assigning non abritrary, unique identifuers, such as unique user names or
ascending serial numbers. (ref bailis)

\item Maintaining consistency of counters supporting arbitrary operations, such
as bank account balance, or stock of an item. 

\item Acquiring a finite resource, such as tickets or airplane seats. 

\item Ensuring that a resource is used only $n$ times, such as resetting a
password with a reset token and using it only once. 
\end{enumerate}

% There are other invariants that require a consistency level in between
 Between these two extremes, there are many other consistency models. For
 instance, the Atomic visibility model(ref) can be used for cases that
 require all parts of a data item to be viewed consistently, but does not require
 the most recent version of a data item. For the following cases, 
 atomic visibility can maintain correctness at a cost lower than strict
 serializability: 
% TODO I think these examples are very abstract. I better replace them with more
% tangible ones. 
\begin{enumerate}
\item Maintaining materialized views.
\item Maintaining foreign key constraints.
\item Maintaining materialized views.
\end{enumerate}

% The problem is that using all these consistency levels in applications 
% is not easy to express or reason about. 
It is not hard to find many distributed applications that include use cases
requiring more than one of the consistency models we described here, such as social media
platforms, E-commerce, games...etc. When these applications must service millions of
clients across the globe correctly, with competitive performance and
availability, selecting the correct consistency policy becomes crucial.
Selecting the strongest policy can have drastic negative effects on availability, while
resorting to eventual consistency can cause violation of correctness invariants.
For instance, authors of (MDCC) conducted part of evaluation to their Paxos-based commit
protocol by comparing the performance of TPC-C transactions when executed under eventual consistency  
, two-phase commit  and their protocol itself. It is not surprising that in all cases, the eventually
consistent protocol was by far the most
performant. However, using only this consistency level cannot guarantee that
some transactions, such as the product buy request will behave correctly, as
this would require strong consistency to maintain the invariant that stock must
remain positive (assuming this is an application requirement!) \\

% How are consistency policies defined? In terms of what?
% I think i will move this def upwards when I start talking about strict
% serializability. Not sure though if I need to define how a consistency policy
% is defined. 
How can programmers specify a consistency policy? 
A consistency policy generally limits possible orderings and concurrency among
operations executed in parallel over data. The nature of data and operations
greatly influences the complexity of the consistency policy definition and
complexity. For instance, linearizability(ref) is concerned with ordering single
operations over a single data item. While a useful and comprehensible theoretical
definition, it applies only to a very narrow subset of real-world operation
abstractions and data representations. It could, for instance be used to model adding
two numbers that occupy only a single memory location (assuming accesses to
memory locations are atomic). But it would fail to represent applying the ++
operator in Java to longs (which occupy two memory locations), not to mention
modeling transactions touching multiple data items, possibly partitioned over many
machines and/or replicated. Strict seriailzability could be thought of as
linearizability that covers grouped operations (transactions) and groups of
items. However, it does not cover the semantics of replicated data items.\\

From the above discussion, we can see how important it is to precisely define
replication and placement strategies, units of data and operations in order to
be able to correctly argue about consistency properties of an application. Yet,
current frameworks are either concerned with strong,
or very weak consistency models, no concrete definitions of data units or
abstractions of replications. 

%For relational databases,
%transaction isolation levels can be used. In Cassandra, a consistency level can
%be specified for all read-write operations. The problem with such approaches, is
%that correctness invariants are usually described in terms of the state of data
%before and after applying an operation(what refs can I list here?) 
%(e.g a transaction or update function) to
%it. However, it is not always clear what constitutes a data unit, or an
%operation unit. One could argue that a transaction serves as an abstraction of
%an operation unit, but then how can we guarantee that all parts of a data unit
%that need to be updated in order to maintain an invariant are actually updated?
%Even worse, when the data is replicated, it could be that updates to different
%parts of a data unit are propagated out of order, or in different orders to
%different replicas. The consistency of a data unit is also the result of complex
%interactions of reads and writes, and depends on the consistency level of both.
%For instance, for data to be consistent in Cassandra, it is not enough to only
%write to a quorum of nodes for all elements of a data item, but all reads of
%that data item must be from a quorum as well. 

% This is unfortunate given the impact consistency level can have on performance
% and how choosing the wrong level can impact program correctness. I can here
% show evaluation results from MDCC paper.
(I want to say here that current tools do not provide suitable abstractions to
represent multi-component, replicated data items, operations units, how to
enforce consistency requirements on data. I also need to show somewhere that
consistency is a property of data.)\\

We have been investigating ways to express consistency properties of
applications, and came up with an approach that builds upon two observations, the
first is that consistency is a property of data, not operations. Consistency
invariants are commonly expressed in terms of a transitions from a state to the
next by a transactions, and then examining the validity of the new state. It
makes sense then , to express consistency as a property of data, rather than
operations, which is what is done in many frameworks (transactions, Cassandra
consistency policies). Authors of (atomic sets) exploit this observation, and
introduce new programming language constructs that allow expressing whether
accesses to data should be linearizable, then depend on the language compiler to
actually insert synchronization constructs whenever needed. The second
observation is that, correctness invariants over data are not temporal, hence
neither is the consistency policy over data. This was explained in (the case for
invariant-based...bailis). 

% We propose a solution, based on observing that invariants on data are not
% temporal, as shown by Bailis, also shown before in the work on atomic sets.
In this paper, we present Data Centric Cloud Types, a programming language that
exploits the previous two observations to encode consistency properties as data
types. Our language is built as an extension to Cloud Types (ref), 
a distributed programming language that provides high-level abstractions to replicated
data and operations applied to it. The runtime of our language makes use of
types encoding 
consistency information to allow more concurrent operations, potentially
improving performance. \\

The rest of this paper is organized as follows: In Section 2 we overview related
work we employed to design and implement the language and its runtime,
Section 3 formally describes our language's syntax and
semantics. In Section 4, we describe how the runtime of the language orders
read/write operations through the commit protocol, exploiting consistency types. 
Section 5 describes the current implementation of the language and shows preliminary evaluation
results. Finally, Section 6 outlines future work and concludes. 

% The idea is to attach consistency policies to data. In the work of atomic
% sets, it is not clear how transactions working on different sets interact and
% how they should be ordered. We contribute by showing how to order them in a
% way that preseves correctness, depending on work by Adya.

% We outline the language specification that contains sets with policies, which
% is built on top of Cloud types language.

% We show examples of common use cases, consistency policies attached and so on.

% Then we go further and show the commit protocol, which orders transactions and
% specifies the number of replicas to be contacted, what is really useful here
% is that the cost model becomes clearer (really?) 

% Finally we discuss future extensions and possible integration with current
% storage systems or languages. 
Replication requires every write issued by system clients to be
propagated across all replicas. Furthermore, concurrent, or out-of-order writes
must be ordered in a way that does not violate application correctness criteria.  


