\documentclass[preprint, numbers]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% numbers       To obtain numeric citation style instead of author/year.

\usepackage{amsmath}

\newcommand{\cL}{{\cal L}}

%TODO
% 1) find a way to handle nestings, check the work of atomic sets and loci again
% this was my problem because of assuming that nested levels of consistency in
% an operation results imply the same things when talking about nested data
% regions.
% 2) define all version combinations for a number of cosistency policies, make
% it clear what can and cannot be supported.
% so in theory everything can be defined in terms of current versions, and how
% next versions relate to each other in a set. 
% 3) find a way to combine this with the mixing theorem of Adya, 
% I state that my system does not assume transactions know what they are doing,
% and also makes it clear that we need to write at minimum isolation level
% declared on a set.
% TODO what is the state in database systems for atomicity of individual sql
% statements? Can we guarantee isolation level 3 if sql statements are not
% atomic?
% TODO shorten abstract, Nate says too wordy.
% TODO future work: nesting and intersection of consistent regions.
% TODO think whether or not to include causal consistency.

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{20yy}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

% Uncomment the publication rights you want to use.
%\publicationrights{transferred}
%\publicationrights{licensed}     % this is the default
%\publicationrights{author-pays}

%\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{Data-centric Consistency Policies} % 'preprint' option specified.

\title{Data-centric Consistency Policies}
\subtitle{A theory and programming model for distributed applications}

\authorinfo{Nosheen Zaza}
           {Universit\`a della Svizzera italiana (USI)}
           {nosheen.zaza@usi.ch}
\authorinfo{Nathaniel Nystrom}
           {Universit\`a della Svizzera italiana (USI)}
           {nate.nystrom@usi.ch}

\maketitle

\begin{abstract}
The consistency level enforced by operations on replicated, distributed data is 
an important parameter in distributed applications, as it impacts correctness, 
performance and availability. Nowadays, it is very common to find various consistency
levels used in a single application, however, current frameworks do not facilitate
working with and reasoning about different consistency properties of an application. 
Furthermore, the problem of defining the semantics of operations enforcing different 
consistency levels has not been well defined or studied. We propose a new
approach for specifying consistency properties based on an important observation: 
correctness criteria and invariants are a property of data, not operations, hence it is 
reasonable to enable defining the consistency properties required to enforce them on data 
rather than operations. We have defined a theoretical model for data-centric reasoning about consistency
properties, and designed a domain-specific programming language we call Data Centric Cloud Types, that enables 
declaring consistency properties, along with a type system to check the compatibility of declared consistency 
properties. The benefits of this language are programs with clearer consistency properties which are 
easier to define and reason about, and the possibility of optimising runtime and commit protocols to enable 
exploiting consistency property definitions to enhance performance.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore,
% you may leave them out
%\terms
%term1, term2

\keywords
distributed systems, domain-specific programming languages.

\section{Introduction}
In modern distributed systems, data is often replicated 
across several nodes. Replication primarily contributes to making distributed 
applications more resilient to failure, and allowing the placement of data closer to clients, 
thus reducing communication delays especially for geo-distributed applications. 
However, managing the consistency of replicated data is a well-known, nontrivial
problem. Ideally, all clients must observe the most recent, correct (according to
application specification) data at all time for the entire store. Achieving this
consistency level through linearizability or serializability entails well
documented costs in terms of latency, availability and partition
tolerance. For this reason, many weaker consistency levels have been proposed,
such as eventual consistency, causal consistency, atomic visibility and others. 

Many storage systems allow programmers to specify a consistency level per
operation, or per sequence of operations that represent a logical unit of work.
However, mapping high application-level consistency requirements to  a combination of
low-level consistency settings on operations is a tedious task. (examples,
cassandra combinations, anomalies when mixing sql consistency levels).

To deal with this problem, we propose a high level, data-centric model that allows developers to declaratively state
consistency requirements for different parts of an application. Our approach is
based on  the following observation: consistency levels are described in terms
of ordering restrictions of concurrent operations touching a common set of objects, for which
a certain invariant must hold. Since the invariants are related to the objects
themselves, it makes sense to enable programmers to declare the consistency
requirements itself on those common objects. As a simple example (counter
example and serializability).
The contributions we make are the following 
\begin{itemize}
  \item A model for describing data regions annotated with consistency
    properties, and assigning suitable isolation levels for individual
    operations, as well as sequences of operations interacting with these
    regions, such that these consistency properties are maintained.
   
  \item A domain specific programming language supporting 3 useful consistency
    properties: eventual consistency, monotonic atomic view, and serializability.
\end{itemize}

\section{System Model}
(ANOTHER STORY)
serial came from serial source
causal from causal, all items causally related
eventual from eventual source.

we flip the reasoning, annotating different schema parts with guarantees needed
for the store.

all operations must execute at isolation levels compatible with the store, what
is interesting is that we define actions on data from multiple sets, and then
different parts of the action are assigned suitable isolation levels, and
executed against suitable store.

hence, our model allows seamless operations on different stores, and the type
system ensures that program actions respect the consistencies, by disallowing
operatiosn 


(using the above story, I can get rid of the damn causality in terms of version
problem.)

I need to solve nesting of regions problem

weaker containing stronger = ok
stronger containing weaker = not ok


I need to solve temporary merging of sets problem, and then guarantees for other
other operatiosn operating on the same isolation level.
same as above, + any merge on action level is treated as a permanent merge, for
safety
too restrictive, but what to do?

I need to specify the interface a store needs to support to be a suitable
backend for our system, or specify the guarantees of the store.
could just mention quelea

I need to specify allowed operation consistencies against sets (here I can cite
the issue from the book)
allow consistencies? no writes at a higher level (not needed), no writes at a
lower level (violation of safety), no writes at a differnt level (for now we
only included totally ordered policies)

finally show the god damn example! perhaps contrast it with the same thing built
using two  or more different databases, with manual assignment of consistency
and stuff.


then the version thingie will be useful, for implementation, so I still need to
figure out which versions should be allowed in a causally consistent set! 
However, I could as well forget about it for now.

but before all that, I need to introduce 

perhaps looking at sagas as nate said could be useful.

Our system model splits the domain of stored objects into a collection of named,
disjoint regions Set s = \{x, y, z..\}. Each
region contains objects that share a correctness invariant. 
Each object has the following attribute vector (version, replica\_id, action\_id) attached,  where
version is an integer that starts at 0 for all store objects at the start of a
program, and is incremented after each write (including a merge of incoming
versions from other replicas), version -1 means that the object is deleted.
replica\_id is an integer identifier of the replica storing the object. and
action\_id is the action that wrote this version of the object. An action is
assigned to read/write operations that perform a single logical task. Either all
operations of an action succeed or all fail and the action is rolled back,
hence. The minimum guarantee for actions is atomicity within the boundaries of
each touched set. We will see through example later why this is a useful, more
permissive property that total atomicity.

In our model, we reason about read/write operation. Each operation has the
attribute vector (replica\_id, action\_id) which are the same as those for the
data. replica\_id specified the replica from which the read/write was issued,
and action\_id specifies the containing action. In our system, every operation
is contained within an action. An action may contain only one operation.

Now, we define a consistency policy of a region. A consistency policy defines 1)
the conditions under which versions in a set are made visible for subsequent
reads/writes, and 2) version transitions allowed by writes to a set. attribute
vectors for objects and actions, as well as set boundaries parameterize
consistency policies. Below we show some consistency properties defined
in terms of our region and operation patameters:

\begin{itemize}
  \item any: it is possible for any write operation to write any data.
  \item monotonic-noncoherent: any write must be to a newer version, however,
    there is no restriction among elements in the set.
  \item coherent-nonmonotonic: all objects in a set are at the same version.
    however, it is not required for the steo to be monotonic.
  \item coherent-monotonic: all objects are at the same version, writes must
    transform all items to a more recent version.
  \item latest: all objects are at the most recent revision.
  \item how to represent causal restrictions? 
\end{itemize}

As for reads in our model, the result of a read is considered to be stored in a
local region, for which the following vector is stored:  (version, action\_id,
source\_consistency) Any reads from local sets generate a similar set.

\subsection{Comparison to traditional consistency definitions}
Our data centric approach aims to avoid needing th repeat isolation 
requirements for each transaction that touches data requiring isolated access
(TODO I better read how the atomic sets people motivate their talk)
and also protect data from misbehaving transactions. Our approach is pragmatic,
and aims to reduce the need of monitoring long sequences of transaction, in
order to track possible orders (TODO how accurate is that? I need to find a
concrete example.)

can we think if our regions as a partitioned shim layer?

problems with trasaction chains:
we can get anomalies such as that in the book, however, if we have a policy that
always governs all transactions related to a data region, we can avoid
anomalies, while hopefully not degrading performance.
know what they are doing:


\subsection{mapping consistency annotations and actions to transactions with
  isolation levels}

I could start first with an instance implementation, which is ours.



%Hence, in the system, we specify the strongest guarantee a data regions gives
%us, in terms of observable combinations of versions, which can be thought as a
%finer-grained versions of what a whole store provides. This makes reasoning about data much simpler.
%I could motivate this as a mini-version of knowing the semantics of your store,/
%like really the precise semantics! This affects how you issue your reads and
%writes and stuff, from where you can read where you can write, additional
%operations you need to do to get out more, we do all this for the granularity
%the programmer chooses! No more confusing read or write interactions, and
%everything is tracked for safety and ease of debugging (ease of debugging is
%something I did not think about before), it also gives us a better way to
%optimize runtime and so. Hence, we care about the resulting data, not the
%operations that resulting in data with certain properties.
%

%version id 
%action id.
%session id.
%version count (replication factor).
%data source, same object (for write after read), or external.

%each data region can contain one or more items, regions are disjoint, we
%describe in the region the highest visibility guarantee that the region can
%provide, in terms of region coherence. Concretely, in order of enforcement cost
%(allowed concurrency, that is, possible concurrent operation permutations)

%any: any data we can get, but it cannot come out of thin air
%diagnosis: if we issue two reads A and B where B happens after A, possible to observe at B a value written
%before A, different parts at different versions possible. (I started to mix in operation properties, not good!)
%write behavior: we can read any version form the set or external source, and
%write to the set.
%%local 
%%local_latest let me ignore local semantics for now.
%coherent: at the same revision, however we could go back in time.
%diagnosis, we could observe older versions, however for all items in the set,
%they are at the same revision
%
%monotonic-noncoherent: for individual items, either same version observed before
%or newer, however, no coherence. 
%monotonic-coherent: same as above with coherence.
%latest: always latest version written of data.

%My model does not support causality, because there is no distinction based on
%individual operations, however, this must be handled when defining actions (need
%to think about that). Actually for causality, I have never seem someone who
%pulls comments then posts then decides to display comments unrelated to a post!
%the solution would be merging the set model with suitabe client-side constructs
%for handling proper output of fetched data, consider the actor model combined
%with futures for instance. We will show how to merge sets with client-side
%constructs for very controllable consistency control.
%(Coming to think about it, even ramp property is some form of causal
%consistency!) 
%company like a good example
%deletion of information currently viewed a good example of cases not even cared
%about
%
%What the store really sees and maps to is too low-level (dog slide from bailis
%work), what is the point of very intricate definitions then? This is why my
%policies are specified in terms of reads and writes.
%
%now it is the job of the programmer to specify related regions and annotate them
%with consistency level, however, what guarantees do we have for operations? how
%are they assigned different isolation levels?
%further more, how can we ensure integrity of data according to the sequential
%spec?
%
%asnwer is, we give pragmatic operations, manifesting the fact that operations
%fail, happen out of order and may (again starting to overcomplicate things )
%note thta performance and consistency are differnet issues, we give programmers
%two modes of sequencing operation within actions. the action itself can be
%interleaved. 
%
%We argue that assigning policies to sets does not degrade expressivenes too
%much, many consistency properties can be expressed in our model, I need to list
%what can and cannot be described, I can use the taxonomy of HAT for that
%purpose.

%in a way, assigning consistency poicies to transaction gives a certain guarantee
%for the duration of the transaction, about data observed in the transaction,
%however, we argue that this is not enough when arguing about a system as a
%whole, with possibly future operations to be added.
%
%I am thinking that, predicate problems are an instance of a problem with a
%larger set requiring certain consistency (the set of all rows of a type),
%containing a smaller set with other consistency requirements, however,
%predicates contain dynamic data, so the set is also dynamic.
%
%We model RDTs in a way similar to Burckhardt's(ref)
%We assume separate conflict resolution mechanism for operations.

\section{Language implementation}
3 isolation levels for actions Srtict serializability, Atomic visibility and
Eventual consistency by using eventually consistent RDTs. 

%2 kinds of data types, local and cloud.
%each client forks a local revision derived from a node it is connected to.
%the revision is partial, revision contents depend on data set declarations.
%an isolation level on a data set specified when concurrent observers (other actions)
%can observe data, and where they can write it.
%serial, means no concurrent actions that contain a write.
%snapshot, means no concurrent actions until all.
%ec, means concurrent reads and writes are possible at anytime.
%
%all operations in a session are async (similar to actor model), unless otherwise
%specified by the programmer.
%
%all operations in separate sessions are async, unless otherwise specified by the
%policy of touched data.
%
\section{Example Language}
\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}


\end{document}
